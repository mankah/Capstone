{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ca6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6504f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_train_h1n1.csv', index_col= 'respondent_id')\n",
    "X_test = pd.read_csv('data/X_test_h1n1.csv', index_col= 'respondent_id')\n",
    "y_train = pd.read_csv('data/y_train_h1n1.csv', index_col= 'respondent_id')\n",
    "y_test = pd.read_csv('data/y_test_h1h1.csv', index_col= 'respondent_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['h1n1_vaccine']\n",
    "y_test = y_test['h1n1_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72cdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes('object')\n",
    "X_train_num = X_train.select_dtypes(['float64', 'int64'])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([('categorical', cat_pipe, X_train_cat.columns),\n",
    "                                 ('numerical', num_pipe, X_train_num.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61843a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "       'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region',\n",
       "       'census_msa'],\n",
       "      dtype=...\n",
       "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "       'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "       'household_children'],\n",
       "      dtype='object'))])),\n",
       "                ('smote', SMOTE(random_state=42)),\n",
       "                ('rfc', RandomForestClassifier(n_jobs=-2, verbose=1))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe = imbPipeline(steps=[\n",
    "    ('trans', transformer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rfc', RandomForestClassifier(verbose=1, n_jobs=-2))\n",
    "])\n",
    "\n",
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec73f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.8s remaining:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cv_score = cross_val_score(model_pipe, X_train, y_train, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6660eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83449825, 0.8349975 , 0.83275087, 0.83799301, 0.83325012])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387aefae",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb99cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_2 = imbPipeline(steps=[\n",
    "    ('trans', transformer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rfc', RandomForestClassifier(verbose=1, n_jobs=-2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a848f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rfc__max_depth': list(range(10,100,10)),\n",
    "    'rfc__criterion': ['gini', 'entropy'],\n",
    "    'rfc__n_estimators': list(range(100,250,50)),\n",
    "    'rfc__min_samples_leaf': list(range(2,10,2)),\n",
    "    'rfc__min_samples_split': list(range(2,10,2)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099be8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 864 candidates, totalling 2592 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('trans',\n",
       "                                        ColumnTransformer(transformers=[('categorical',\n",
       "                                                                         Pipeline(steps=[('impute',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ohe',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "       'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_...\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "       'household_children'],\n",
       "      dtype='object'))])),\n",
       "                                       ('smote', SMOTE(random_state=42)),\n",
       "                                       ('rfc',\n",
       "                                        RandomForestClassifier(n_jobs=-2,\n",
       "                                                               verbose=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
       "                         'rfc__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "                         'rfc__min_samples_leaf': [2, 4, 6, 8],\n",
       "                         'rfc__min_samples_split': [2, 4, 6, 8],\n",
       "                         'rfc__n_estimators': [100, 150, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc = GridSearchCV(model_pipe_2, params, n_jobs=-1, verbose=3, cv = 3)\n",
    "gs_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c0bec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__criterion': 'entropy',\n",
       " 'rfc__max_depth': 40,\n",
       " 'rfc__min_samples_leaf': 6,\n",
       " 'rfc__min_samples_split': 8,\n",
       " 'rfc__n_estimators': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c09c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 223.7min remaining: 335.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 223.9min finished\n"
     ]
    }
   ],
   "source": [
    "rfc_cv_1 = cross_val_score(gs_rfc, X_train, y_train, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de66fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83349975, 0.8349975 , 0.83474788, 0.83674488, 0.83474788])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296fda0",
   "metadata": {},
   "source": [
    "## Gradiant Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5d6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe_3 = imbPipeline(steps=[\n",
    "    ('trans', transformer),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('gbc', GradientBoostingClassifier(verbose=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0597111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('trans',\n",
       "   ColumnTransformer(transformers=[('categorical',\n",
       "                                    Pipeline(steps=[('impute',\n",
       "                                                     SimpleImputer(strategy='most_frequent')),\n",
       "                                                    ('ohe',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                   sparse=False))]),\n",
       "                                    Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "          'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region',\n",
       "          'census_msa'],\n",
       "         dtype='object')),\n",
       "                                   ('numerical',\n",
       "                                    P...\n",
       "          'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "          'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "          'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "          'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "          'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "          'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "          'household_children'],\n",
       "         dtype='object'))])),\n",
       "  ('smote', SMOTE(random_state=42)),\n",
       "  ('gbc', GradientBoostingClassifier(verbose=3))],\n",
       " 'verbose': False,\n",
       " 'trans': ColumnTransformer(transformers=[('categorical',\n",
       "                                  Pipeline(steps=[('impute',\n",
       "                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                  ('ohe',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                 sparse=False))]),\n",
       "                                  Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "        'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region',\n",
       "        'census_msa'],\n",
       "       dtype='object')),\n",
       "                                 ('numerical',\n",
       "                                  P...\n",
       "        'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "        'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "        'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "        'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "        'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "        'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "        'household_children'],\n",
       "       dtype='object'))]),\n",
       " 'smote': SMOTE(random_state=42),\n",
       " 'gbc': GradientBoostingClassifier(verbose=3),\n",
       " 'trans__n_jobs': None,\n",
       " 'trans__remainder': 'drop',\n",
       " 'trans__sparse_threshold': 0.3,\n",
       " 'trans__transformer_weights': None,\n",
       " 'trans__transformers': [('categorical',\n",
       "   Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent')),\n",
       "                   ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))]),\n",
       "   Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "          'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region',\n",
       "          'census_msa'],\n",
       "         dtype='object')),\n",
       "  ('numerical',\n",
       "   Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent'))]),\n",
       "   Index(['h1n1_concern', 'h1n1_knowledge', 'behavioral_antiviral_meds',\n",
       "          'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "          'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "          'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "          'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "          'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "          'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "          'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "          'household_children'],\n",
       "         dtype='object'))],\n",
       " 'trans__verbose': False,\n",
       " 'trans__categorical': Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent')),\n",
       "                 ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))]),\n",
       " 'trans__numerical': Pipeline(steps=[('impute', SimpleImputer(strategy='most_frequent'))]),\n",
       " 'trans__categorical__memory': None,\n",
       " 'trans__categorical__steps': [('impute',\n",
       "   SimpleImputer(strategy='most_frequent')),\n",
       "  ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))],\n",
       " 'trans__categorical__verbose': False,\n",
       " 'trans__categorical__impute': SimpleImputer(strategy='most_frequent'),\n",
       " 'trans__categorical__ohe': OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
       " 'trans__categorical__impute__add_indicator': False,\n",
       " 'trans__categorical__impute__copy': True,\n",
       " 'trans__categorical__impute__fill_value': None,\n",
       " 'trans__categorical__impute__missing_values': nan,\n",
       " 'trans__categorical__impute__strategy': 'most_frequent',\n",
       " 'trans__categorical__impute__verbose': 0,\n",
       " 'trans__categorical__ohe__categories': 'auto',\n",
       " 'trans__categorical__ohe__drop': None,\n",
       " 'trans__categorical__ohe__dtype': numpy.float64,\n",
       " 'trans__categorical__ohe__handle_unknown': 'ignore',\n",
       " 'trans__categorical__ohe__sparse': False,\n",
       " 'trans__numerical__memory': None,\n",
       " 'trans__numerical__steps': [('impute',\n",
       "   SimpleImputer(strategy='most_frequent'))],\n",
       " 'trans__numerical__verbose': False,\n",
       " 'trans__numerical__impute': SimpleImputer(strategy='most_frequent'),\n",
       " 'trans__numerical__impute__add_indicator': False,\n",
       " 'trans__numerical__impute__copy': True,\n",
       " 'trans__numerical__impute__fill_value': None,\n",
       " 'trans__numerical__impute__missing_values': nan,\n",
       " 'trans__numerical__impute__strategy': 'most_frequent',\n",
       " 'trans__numerical__impute__verbose': 0,\n",
       " 'smote__k_neighbors': 5,\n",
       " 'smote__n_jobs': None,\n",
       " 'smote__random_state': 42,\n",
       " 'smote__sampling_strategy': 'auto',\n",
       " 'gbc__ccp_alpha': 0.0,\n",
       " 'gbc__criterion': 'friedman_mse',\n",
       " 'gbc__init': None,\n",
       " 'gbc__learning_rate': 0.1,\n",
       " 'gbc__loss': 'deviance',\n",
       " 'gbc__max_depth': 3,\n",
       " 'gbc__max_features': None,\n",
       " 'gbc__max_leaf_nodes': None,\n",
       " 'gbc__min_impurity_decrease': 0.0,\n",
       " 'gbc__min_impurity_split': None,\n",
       " 'gbc__min_samples_leaf': 1,\n",
       " 'gbc__min_samples_split': 2,\n",
       " 'gbc__min_weight_fraction_leaf': 0.0,\n",
       " 'gbc__n_estimators': 100,\n",
       " 'gbc__n_iter_no_change': None,\n",
       " 'gbc__random_state': None,\n",
       " 'gbc__subsample': 1.0,\n",
       " 'gbc__tol': 0.0001,\n",
       " 'gbc__validation_fraction': 0.1,\n",
       " 'gbc__verbose': 3,\n",
       " 'gbc__warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe_3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2512969",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gbc__learning_rate': [0.001, 0.01, 0.1, .5, .9],\n",
    "    'gbc__n_estimators': list(range(100,250,50)),\n",
    "    'gbc__min_samples_leaf': list(range(2,10,2)),\n",
    "    'gbc__min_samples_split': list(range(2,10,2)),\n",
    "    'gbc__max_features': list(range(0,200,50))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ff8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 960 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manav Kahlon\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79266145 0.79146278 0.79520703 0.79016473 0.77493819 0.78033052\n",
      " 0.78881668 0.78362472 0.79425897 0.7755375  0.77733468 0.79081379\n",
      " 0.79286055 0.77518782 0.78846722 0.77403958 0.79390878 0.77453881\n",
      " 0.79061389 0.78921606 0.79540734 0.78936583 0.78736892 0.78946591\n",
      " 0.77793359 0.78951559 0.77418935 0.77513788 0.78627103 0.79485791\n",
      " 0.77548734 0.78976521 0.79735418 0.78801806 0.78756861 0.79001482\n",
      " 0.78222689 0.79355933 0.79425839 0.79001482 0.77833328 0.78906629\n",
      " 0.79216149 0.78841741 0.79395944 0.787319   0.77648593 0.79011466\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.80015018 0.80039945 0.80718939 0.80034985 0.80034953 0.80674\n",
      " 0.80000032 0.80004998 0.80604106 0.80089909 0.80009987 0.80634067\n",
      " 0.80029995 0.80079884 0.80713942 0.80089903 0.80079882 0.80649035\n",
      " 0.79995048 0.80054923 0.80669013 0.80025002 0.80034952 0.80639054\n",
      " 0.79970075 0.80019971 0.80664022 0.80044972 0.80059913 0.80718936\n",
      " 0.80020009 0.80019976 0.80654031 0.80039979 0.80059913 0.80688976\n",
      " 0.79905171 0.80074891 0.80669005 0.80059951 0.80039947 0.8066901\n",
      " 0.7990018  0.80014982 0.80713946 0.79990055 0.80069899 0.80708951\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.8342487  0.83614583 0.83664514 0.83250129 0.83574644 0.83679492\n",
      " 0.83300057 0.83694468 0.83604605 0.83439835 0.83639548 0.83739403\n",
      " 0.83409885 0.83514738 0.83729425 0.83384924 0.83584634 0.8374439\n",
      " 0.83549682 0.83594618 0.83684484 0.83330004 0.83544697 0.83789328\n",
      " 0.83419875 0.83559675 0.83624573 0.83414879 0.83589631 0.83729418\n",
      " 0.83429854 0.83599615 0.8372443  0.8345982  0.83539702 0.8384425\n",
      " 0.83399904 0.83594612 0.83694462 0.83369944 0.83599608 0.83729423\n",
      " 0.83325012 0.83559669 0.83619587 0.83335    0.83564664 0.83664516\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83449844 0.8321519  0.83180233 0.83524723 0.83125314 0.82775847\n",
      " 0.83424863 0.83424866 0.82955573 0.83275102 0.83030465 0.82800797\n",
      " 0.83469808 0.83210195 0.8295058  0.83280099 0.83200208 0.83030468\n",
      " 0.83544694 0.83305045 0.82925634 0.83389926 0.83145296 0.83000523\n",
      " 0.83444834 0.83010502 0.83075403 0.83394927 0.83185217 0.82885681\n",
      " 0.83509754 0.83364955 0.83090357 0.83255131 0.83295091 0.82995519\n",
      " 0.83409893 0.83120329 0.83030457 0.83514752 0.83250123 0.83045433\n",
      " 0.83145296 0.83210194 0.83075406 0.83494759 0.83185242 0.82990522\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82351465 0.82431364 0.82056918 0.82356485 0.82261622 0.81687483\n",
      " 0.82601114 0.82026976 0.81992008 0.82406401 0.81962062 0.81922126\n",
      " 0.82411401 0.82351485 0.81772347 0.82441342 0.82341489 0.81707441\n",
      " 0.8252123  0.82056929 0.81687472 0.82421387 0.82171741 0.82061929\n",
      " 0.823365   0.82031964 0.81907144 0.82371469 0.82326503 0.81997004\n",
      " 0.82281578 0.82116843 0.8185724  0.82406398 0.82141802 0.81797306\n",
      " 0.82536199 0.82046937 0.81717427 0.82621075 0.82041953 0.81922123\n",
      " 0.82341502 0.81837251 0.81767363 0.82646041 0.82161768 0.81787329\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3150           26.04s\n",
      "         2           1.2528           24.91s\n",
      "         3           1.2028           23.67s\n",
      "         4           1.1592           22.98s\n",
      "         5           1.1200           22.73s\n",
      "         6           1.0883           22.24s\n",
      "         7           1.0610           21.39s\n",
      "         8           1.0380           21.13s\n",
      "         9           1.0168           20.74s\n",
      "        10           0.9966           20.38s\n",
      "        11           0.9786           20.15s\n",
      "        12           0.9616           19.75s\n",
      "        13           0.9452           19.52s\n",
      "        14           0.9302           18.95s\n",
      "        15           0.9160           18.64s\n",
      "        16           0.9047           18.35s\n",
      "        17           0.8868           18.26s\n",
      "        18           0.8759           18.32s\n",
      "        19           0.8645           18.40s\n",
      "        20           0.8537           18.18s\n",
      "        21           0.8413           17.87s\n",
      "        22           0.8329           17.78s\n",
      "        23           0.8238           17.68s\n",
      "        24           0.8146           17.42s\n",
      "        25           0.8043           17.22s\n",
      "        26           0.7958           17.22s\n",
      "        27           0.7898           17.15s\n",
      "        28           0.7785           17.18s\n",
      "        29           0.7691           17.18s\n",
      "        30           0.7611           17.21s\n",
      "        31           0.7506           17.15s\n",
      "        32           0.7410           17.27s\n",
      "        33           0.7358           17.36s\n",
      "        34           0.7283           17.65s\n",
      "        35           0.7246           17.91s\n",
      "        36           0.7192           18.05s\n",
      "        37           0.7142           17.99s\n",
      "        38           0.7087           17.99s\n",
      "        39           0.7038           17.94s\n",
      "        40           0.6973           17.89s\n",
      "        41           0.6910           17.69s\n",
      "        42           0.6871           17.61s\n",
      "        43           0.6813           17.46s\n",
      "        44           0.6773           17.37s\n",
      "        45           0.6738           17.21s\n",
      "        46           0.6678           17.01s\n",
      "        47           0.6630           16.87s\n",
      "        48           0.6602           16.67s\n",
      "        49           0.6561           16.48s\n",
      "        50           0.6515           16.30s\n",
      "        51           0.6482           16.12s\n",
      "        52           0.6445           15.94s\n",
      "        53           0.6417           15.81s\n",
      "        54           0.6384           15.63s\n",
      "        55           0.6340           15.42s\n",
      "        56           0.6297           15.28s\n",
      "        57           0.6257           15.10s\n",
      "        58           0.6228           14.94s\n",
      "        59           0.6201           14.81s\n",
      "        60           0.6173           14.62s\n",
      "        61           0.6151           14.47s\n",
      "        62           0.6111           14.35s\n",
      "        63           0.6088           14.17s\n",
      "        64           0.6061           14.03s\n",
      "        65           0.6030           13.91s\n",
      "        66           0.6002           13.74s\n",
      "        67           0.5976           13.60s\n",
      "        68           0.5958           13.47s\n",
      "        69           0.5937           13.33s\n",
      "        70           0.5911           13.20s\n",
      "        71           0.5888           13.07s\n",
      "        72           0.5875           12.95s\n",
      "        73           0.5842           12.79s\n",
      "        74           0.5819           12.68s\n",
      "        75           0.5800           12.53s\n",
      "        76           0.5790           12.41s\n",
      "        77           0.5766           12.29s\n",
      "        78           0.5752           12.15s\n",
      "        79           0.5726           12.03s\n",
      "        80           0.5696           11.91s\n",
      "        81           0.5680           11.78s\n",
      "        82           0.5665           11.66s\n",
      "        83           0.5648           11.56s\n",
      "        84           0.5635           11.43s\n",
      "        85           0.5617           11.30s\n",
      "        86           0.5599           11.19s\n",
      "        87           0.5589           11.07s\n",
      "        88           0.5566           10.95s\n",
      "        89           0.5551           10.84s\n",
      "        90           0.5534           10.70s\n",
      "        91           0.5521           10.59s\n",
      "        92           0.5508           10.48s\n",
      "        93           0.5500           10.36s\n",
      "        94           0.5479           10.25s\n",
      "        95           0.5464           10.15s\n",
      "        96           0.5450           10.03s\n",
      "        97           0.5443            9.92s\n",
      "        98           0.5422            9.81s\n",
      "        99           0.5405            9.69s\n",
      "       100           0.5392            9.59s\n",
      "       101           0.5378            9.48s\n",
      "       102           0.5356            9.36s\n",
      "       103           0.5342            9.25s\n",
      "       104           0.5334            9.16s\n",
      "       105           0.5318            9.03s\n",
      "       106           0.5310            8.93s\n",
      "       107           0.5303            8.84s\n",
      "       108           0.5293            8.73s\n",
      "       109           0.5279            8.62s\n",
      "       110           0.5269            8.53s\n",
      "       111           0.5254            8.42s\n",
      "       112           0.5241            8.31s\n",
      "       113           0.5233            8.21s\n",
      "       114           0.5221            8.11s\n",
      "       115           0.5206            8.00s\n",
      "       116           0.5199            7.90s\n",
      "       117           0.5189            7.79s\n",
      "       118           0.5176            7.69s\n",
      "       119           0.5167            7.59s\n",
      "       120           0.5160            7.49s\n",
      "       121           0.5150            7.39s\n",
      "       122           0.5146            7.30s\n",
      "       123           0.5138            7.19s\n",
      "       124           0.5129            7.09s\n",
      "       125           0.5115            6.99s\n",
      "       126           0.5106            6.89s\n",
      "       127           0.5098            6.79s\n",
      "       128           0.5091            6.69s\n",
      "       129           0.5084            6.58s\n",
      "       130           0.5074            6.49s\n",
      "       131           0.5067            6.39s\n",
      "       132           0.5060            6.29s\n",
      "       133           0.5056            6.20s\n",
      "       134           0.5051            6.10s\n",
      "       135           0.5042            6.00s\n",
      "       136           0.5035            5.90s\n",
      "       137           0.5032            5.81s\n",
      "       138           0.5025            5.71s\n",
      "       139           0.5018            5.61s\n",
      "       140           0.5011            5.52s\n",
      "       141           0.5005            5.42s\n",
      "       142           0.4997            5.32s\n",
      "       143           0.4985            5.23s\n",
      "       144           0.4980            5.13s\n",
      "       145           0.4974            5.04s\n",
      "       146           0.4966            4.94s\n",
      "       147           0.4961            4.85s\n",
      "       148           0.4956            4.75s\n",
      "       149           0.4952            4.66s\n",
      "       150           0.4948            4.56s\n",
      "       151           0.4942            4.47s\n",
      "       152           0.4939            4.38s\n",
      "       153           0.4936            4.28s\n",
      "       154           0.4930            4.19s\n",
      "       155           0.4926            4.10s\n",
      "       156           0.4922            4.00s\n",
      "       157           0.4919            3.91s\n",
      "       158           0.4914            3.82s\n",
      "       159           0.4911            3.72s\n",
      "       160           0.4909            3.63s\n",
      "       161           0.4906            3.54s\n",
      "       162           0.4902            3.45s\n",
      "       163           0.4896            3.35s\n",
      "       164           0.4889            3.26s\n",
      "       165           0.4886            3.17s\n",
      "       166           0.4884            3.08s\n",
      "       167           0.4878            2.98s\n",
      "       168           0.4874            2.89s\n",
      "       169           0.4870            2.80s\n",
      "       170           0.4867            2.71s\n",
      "       171           0.4864            2.61s\n",
      "       172           0.4862            2.52s\n",
      "       173           0.4857            2.43s\n",
      "       174           0.4855            2.34s\n",
      "       175           0.4850            2.25s\n",
      "       176           0.4848            2.16s\n",
      "       177           0.4844            2.07s\n",
      "       178           0.4839            1.98s\n",
      "       179           0.4836            1.89s\n",
      "       180           0.4834            1.80s\n",
      "       181           0.4829            1.71s\n",
      "       182           0.4825            1.62s\n",
      "       183           0.4823            1.53s\n",
      "       184           0.4817            1.43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       185           0.4815            1.34s\n",
      "       186           0.4812            1.25s\n",
      "       187           0.4808            1.16s\n",
      "       188           0.4802            1.07s\n",
      "       189           0.4799            0.98s\n",
      "       190           0.4795            0.89s\n",
      "       191           0.4791            0.80s\n",
      "       192           0.4789            0.71s\n",
      "       193           0.4785            0.62s\n",
      "       194           0.4781            0.54s\n",
      "       195           0.4779            0.45s\n",
      "       196           0.4777            0.36s\n",
      "       197           0.4772            0.27s\n",
      "       198           0.4768            0.18s\n",
      "       199           0.4766            0.09s\n",
      "       200           0.4764            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('trans',\n",
       "                                        ColumnTransformer(transformers=[('categorical',\n",
       "                                                                         Pipeline(steps=[('impute',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ohe',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         Index(['age_group', 'education', 'race', 'sex', 'income_poverty',\n",
       "       'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_...\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'household_adults',\n",
       "       'household_children'],\n",
       "      dtype='object'))])),\n",
       "                                       ('smote', SMOTE(random_state=42)),\n",
       "                                       ('gbc',\n",
       "                                        GradientBoostingClassifier(verbose=3))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'gbc__learning_rate': [0.001, 0.01, 0.1, 0.5, 0.9],\n",
       "                         'gbc__max_features': [0, 50, 100, 150],\n",
       "                         'gbc__min_samples_leaf': [2, 4, 6, 8],\n",
       "                         'gbc__min_samples_split': [2, 4, 6, 8],\n",
       "                         'gbc__n_estimators': [100, 150, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbc = GridSearchCV(model_pipe_3, params, n_jobs=-1, verbose=1, cv = 3)\n",
    "gs_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a96ed76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbc__learning_rate': 0.1,\n",
       " 'gbc__max_features': 50,\n",
       " 'gbc__min_samples_leaf': 6,\n",
       " 'gbc__min_samples_split': 8,\n",
       " 'gbc__n_estimators': 200}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ed56445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 159.1min remaining: 238.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 159.2min finished\n"
     ]
    }
   ],
   "source": [
    "gbc_cv_1 = cross_val_score(gs_gbc, X_train, y_train, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca218827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83849226, 0.83724413, 0.8349975 , 0.83924114, 0.83924114])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_cv_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
